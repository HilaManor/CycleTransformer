output_dir: './results'
db_path: '../databases/102flowers'
db_type: 'flowers'

training_args:
  batch_size: 20
  txt_max_len: 30
  learning_rate: 1e-3 #1e-5
  test_percent: 0.1
  val_percent: 0.1

txt2im_model_args:
  alpha: 10000 
  learning_rate: 1e-3
  noise_dim_percent: 0.2
  g_step: 10
  generator_args:
    nf: 64
    out_dim: 224
    out_channels: 3
    kernel_size: 3
    #num_layers:
  linear_out_dim: 100
  encoder_args:
    name: 'distilbert-base-uncased'

im2txt_model_args:
  encoder_name: 'facebook/deit-small-distilled-patch16-224'
  #decoder_name: 'distilgpt2'
  decoder_name: 'gpt2'
  learning_rate: 1e-5
